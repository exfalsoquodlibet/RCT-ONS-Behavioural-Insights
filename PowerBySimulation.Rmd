---
title: "A-Priori Power Simulation"
author: "Alessia Tosi"
date: "15/01/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this script, I calculate the sample size necessary to detect the minimal effect of practical significance given the desired power using simulation.

The RCT trial design is a two-arm or between-subject design. Stratification was used to control for possible confounding factors with Month of First Selection (Jan-May) as stratifying variable.


### Steps

Our data will be binary (1 if the business has complied on time, 0 otherwise) and we'll analyse them using a generalised linear model with a logit link function (i.e., logistic regression).

We will:

1. Establish the effect that we want to be able to detect (the minimal effect size that is of PRACTICAL significance, i.e. that we want to be able to pick up if it is there) and sample size N

3. Simulate N data for that possible effect, and do the analyse on this simulated data. 

4. Collect the p-value or test statistics.

5. Re-run steps 3-4 a bunch of times (i.e., 1000 repetition). The proportion of times that we'll reject the null hypothesis is the power at that N.

6. To determine a-priori sample size to detect the desired effect for the desired power, we'll search over possible n values of N, re-run steps 3-5 for each value of N, to find the value that yeilds our desire power.


```{r cars}


```

### Step 1: Determine minimal effect of practical significance

The trial focused on the April 2018 data for businesses that newly joined the survey between January and April 2018, and May 2018 data for businesses that newly joined the survey in that month. 

Using the historical data of the ONS Construction Survey, we could calculate the baseline (i.e., control-group) response rate by-deadline. This was the weighted average of the past response rate by-deadline of businesses that newly joined the survey in Jan-May in previous years.
Three categories of baseline response rates depending:

- April baseline for businesses which newly joined in January, February or March (`apr_prev_p0`)
- April baseline for businesses which newly joined in that month (`apr_new_p0`)
- May baseline for businesses which newly joined in that month (`may_new_p0`)

```{r baselines, echo=TRUE}
apr_new_p0 = 0.14
apr_prev_p0 = 0.17
may_new_p0 = 0.29

# control-group baseline as weighted average of past response rate by deadline
baseline_p0 <- (apr_new_p0 + apr_prev_p0*3 + may_new_p0)/5

```

The minimum intervention effect can be seen as the minimum odds ratio of practical interest associated with intervention allocation. In our case, we established that an increase of 4 percentage points in the rate of businesses that respond by the deadline would be consider successful in terms of saving resources for response chasing.

```{r min_effect, echo=TRUE}

# minimum desired effect
min_de <- 0.04

intervention_p1 <- baseline_p0 + min_de

( odds_intervention <-  intervention_p1/(1-intervention_p1) )
( odds_baseline <-  baseline_p0/(1-baseline_p0) )
( odds_ratio <- odds_intervention / odds_baseline )

# minimum desired effect as log-odds given the expected control-group frequency
( beta_logodds <- log(odds_ratio))
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


### References

https://stats.stackexchange.com/questions/22406/power-analysis-for-ordinal-logistic-regression/22410#22410

https://stats.stackexchange.com/questions/35940/simulation-of-logistic-regression-power-analysis-designed-experiments/36040#36040

https://stats.stackexchange.com/questions/111308/why-is-power-analysis-with-logistic-regression-so-liberal-compared-to-chi-square?rq=1

